\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Building A FeedForward Neural Network}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Basics}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Layout of a feedforward network, bias nodes excluded.}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Forward Propagation}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Backpropagation}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-processing Datasets}{4}}
\citation{goldberg2014word2vec}
\citation{mikolovword2vec}
\citation{tang2014learning}
\citation{maas2011learning}
\citation{tang2014coooolll}
\citation{hall1998practical}
\citation{Garner95weka}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Bayesian Probabilities}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Word Embeddings}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Twitter Specific Features}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Selecting Parameters}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Batch Sizes}{6}}
\citation{hochreiter1998vanishing}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Parameter Fine-Tuning Results for the Keras NN}}{7}}
\newlabel{fig:all_in_one}{{2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\# of Hidden Layers}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Size of Hidden Layers}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\# of Epochs and Learning Rate}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Analysing Dataset Representation}{9}}
\citation{tang2014learning}
\citation{tang2014coooolll}
\citation{Kim14}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification}}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Keras vs. Our Own Neural Network}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Further Work}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Convolutional Neural Networks}{10}}
\bibstyle{ieeetr}
\bibdata{main}
\bibcite{goldberg2014word2vec}{1}
\bibcite{mikolovword2vec}{2}
\bibcite{tang2014learning}{3}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{11}}
\bibcite{maas2011learning}{4}
\bibcite{tang2014coooolll}{5}
\bibcite{hall1998practical}{6}
\bibcite{Garner95weka}{7}
\bibcite{hochreiter1998vanishing}{8}
\bibcite{Kim14}{9}
\bibcite{iamtrask}{10}
\bibcite{neuralnet}{11}
\citation{iamtrask}
\citation{neuralnet}
